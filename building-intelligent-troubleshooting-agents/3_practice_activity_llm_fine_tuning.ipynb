{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice activity: LLM fine-tuning\n",
    "\n",
    "**Disclaimer:** Please be aware that the activities in this reading involve resource-intensive tasks such as model training. If you are using outdated hardware or systems with limited processing power, these tasks might take significantly longer to complete, ranging from 30 to 90 minutes, depending on your system's capabilities. To ensure a smoother experience, consider using cloud-based resources or modern hardware optimized for machine learning workloads.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this activity, you'll practice fine-tuning a large language model (LLM) by applying the core steps to a simulated task. Through this hands-on exercise, you'll explore how to prepare a dataset, configure the model, adjust hyperparameters, and deploy a fine-tuned model for sentiment analysis. Each code snippet includes in-depth commentary to help you understand each step and how it applies to real-world applications.\n",
    "\n",
    "By the end of this activity, you will be able to:\n",
    "\n",
    "- Prepare and split task-specific datasets.\n",
    "- Set up an Azure environment for fine-tuning LLMs.\n",
    "- Fine-tune a pretrained model for sentiment classification.\n",
    "- Evaluate and deploy the model for real-time sentiment analysis.\n",
    "- Interpret evaluation metrics like accuracy and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "Imagine you work for a healthcare organization that wants to fine-tune an LLM to automatically analyze patient feedback surveys. Your goal is to adapt the pretrained model to recognize key sentiments and flag any negative feedback for further review by a healthcare specialist. Follow the steps below to practice fine-tuning the LLM for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step process for fine-tuning LLMs\n",
    "\n",
    "This reading will guide you through the following steps:\n",
    "\n",
    "- Step 1: Prepare the dataset\n",
    "- Step 2: Split the dataset\n",
    "- Step 3: Set Up the environment\n",
    "- Step 4: Configure hyperparameters\n",
    "- Step 5: Fine-tune the model\n",
    "- Step 6: Evaluate the model\n",
    "- Step 7: Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the dataset\n",
    "\n",
    "### Dataset collection\n",
    "\n",
    "Collect a dataset of anonymized patient feedback categorized by sentiment—positive, neutral, and negative. Preprocessing includes cleaning, tokenizing, and splitting the data.\n",
    "\n",
    "### Code example: Data cleaning and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Create a noisy dataset\n",
    "data_dict = {\n",
    "    \"text\": [\n",
    "        \" The staff was very kind and attentive to my needs!!! \",\n",
    "        \"The waiting time was too long, and the staff was rude. Visit us at http://hospitalreviews.com\",\n",
    "        \"The doctor answered all my questions...but the facility was outdated. \",\n",
    "        \"The nurse was compassionate & made me feel comfortable!! :) \",\n",
    "        \"I had to wait over an hour before being seen. Unacceptable service! #frustrated\",\n",
    "        \"The check-in process was smooth, but the doctor seemed rushed. Visit https://feedback.com\",\n",
    "        \"Everyone I interacted with was professional and helpful. \"\n",
    "    ],\n",
    "    \"label\": [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\", \"positive\"]\n",
    "}\n",
    "\n",
    "# Convert dataset to a DataFrame\n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data[\"cleaned_text\"] = data[\"text\"].apply(clean_text)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_map = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
    "data[\"label\"] = data[\"label\"].map(label_map)\n",
    "\n",
    "# Tokenize the cleaned text\n",
    "data['tokenized'] = data['cleaned_text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the dataset\n",
    "\n",
    "Split your dataset into training, validation, and test sets. These splits serve distinct purposes: training teaches the model, validation helps tune hyperparameters, and testing offers an unbiased evaluation.\n",
    "\n",
    "### Code example: Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data: 70% training, 15% validation, 15% test\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training Size: {len(train_data)}, Validation Size: {len(val_data)}, Test Size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set up the environment\n",
    "\n",
    "Fine-tune the model in an environment with access to GPU/TPU resources. For this activity, we will use a pretrained BERT model configured for sentiment classification.\n",
    "\n",
    "#### Additional Instructions for GPU Setup\n",
    "\n",
    "- **For cloud environments**: Use platforms like Google Colab or AWS SageMaker for GPU access.\n",
    "- **For local environments**: Install the required libraries and configure CUDA for GPU.\n",
    "\n",
    "### Code example: Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"cleaned_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Tokenize the dataset\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "\n",
    "# Convert labels to int if they are not already\n",
    "train_dataset = train_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "val_dataset = val_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "test_dataset = test_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
    "\n",
    "# Print a sample to confirm input_ids exist\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configure hyperparameters\n",
    "\n",
    "Define hyperparameters to control the model's training process, such as learning rate and batch size.\n",
    "\n",
    "### Learning rate\n",
    "\n",
    "The learning rate controls the size of the updates made to the model's weights during each optimization step. For fine-tuning, a low learning rate—typically between 1e-5 and 5e-5—is crucial. This ensures that updates are gradual, allowing the model to adapt to the new task while preserving the valuable general knowledge learned during pretraining.\n",
    "\n",
    "### Code example: Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# **Explain 'evaluation_strategy':**\n",
    "# This determines when the model is evaluated. 'Epoch' evaluates the model after each training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fine-tune the model\n",
    "\n",
    "Train the model using the prepared dataset and monitor its progress.\n",
    "\n",
    "### Code example: Fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]),\n",
    "    eval_dataset=val_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the model\n",
    "\n",
    "Evaluate the fine-tuned model on the test set using metrics like accuracy and F1 score.\n",
    "\n",
    "### Evaluation metrics\n",
    "\n",
    "Use evaluation metrics that reflect the accuracy and balance of predictions across all classes.\n",
    "\n",
    "### Code example: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Generate predictions\n",
    "test_dataset = test_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = test_dataset[\"label\"]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "\n",
    "# **Explain metric importance**:\n",
    "# High F1 scores indicate balanced performance across all classes, crucial in tasks like sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Deploy the model\n",
    "\n",
    "Save and deploy the model for real-time sentiment analysis.\n",
    "\n",
    "### Code example: Save and Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./fine_tuned_bert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bert\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This activity demonstrates the end-to-end process of fine-tuning a large language model (LLM) for sentiment analysis. From cleaning and tokenizing the dataset to training, evaluating, and deploying the model, each step is designed to give you hands-on experience with the core tasks involved in preparing LLMs for real-world applications. With these skills, you can adapt LLMs for a variety of specialized use cases across industries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
